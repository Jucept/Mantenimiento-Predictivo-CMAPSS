{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ced1020",
   "metadata": {},
   "source": [
    "# Imports y Configuración Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9906586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports y configuración\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Paths\n",
    "ROOT = Path.cwd()\n",
    "DATA_DIR = ROOT / \"CMAPSSData\" \n",
    "RAW_DIR = Path(r\"../CMAPSSData/raw\") \n",
    "EDA_OUT = ROOT / \"eda_outputs\"\n",
    "EDA_OUT.mkdir(exist_ok=True)\n",
    "\n",
    "# Visual defaults\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60e71ac",
   "metadata": {},
   "source": [
    "# Funciones Utilitarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da891ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones reutilizables solicitadas\n",
    "def read_cmapss(path):\n",
    "    \"\"\"Leer archivo C-MAPSS (espacios múltiples) y asignar nombres de columna.\"\"\"\n",
    "    col_names = [\"unit\", \"cycle\", \"op1\", \"op2\", \"op3\"] + [f\"s{i}\" for i in range(1, 22)]\n",
    "    df = pd.read_csv(path, sep=r\"\\s+\", header=None, names=col_names)\n",
    "    return df\n",
    "\n",
    "def compute_rul(df):\n",
    "    \"\"\"Calcular RUL por unit para dataset de entrenamiento.\n",
    "       Devuelve df con nueva columna 'RUL' y rul_per_unit dataframe.\n",
    "    \"\"\"\n",
    "    max_cycle = df.groupby(\"unit\")[\"cycle\"].transform(\"max\")\n",
    "    df = df.copy()\n",
    "    df[\"RUL\"] = max_cycle - df[\"cycle\"]\n",
    "    rul_per_unit = df[[\"unit\", \"cycle\", \"RUL\"]].copy()\n",
    "    return df, rul_per_unit\n",
    "\n",
    "def summary_stats(df):\n",
    "    \"\"\"Resumen con percentiles 25,50,75,99 y missing pct por columna.\"\"\"\n",
    "    stats = df.describe(percentiles=[.25, .5, .75, .99]).T\n",
    "    stats = stats.rename(columns={\"50%\": \"50%\", \"99%\": \"99%\"})\n",
    "    stats[\"missing_pct\"] = df.isna().mean() * 100\n",
    "    cols_keep = [\"count\", \"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"99%\", \"max\", \"missing_pct\"]\n",
    "    return stats[cols_keep].reset_index().rename(columns={\"index\": \"column\"})\n",
    "\n",
    "def per_unit_stats(df):\n",
    "    \"\"\"Estadísticas por unidad: cycles_count, cycle_length, first/last val per sensor (flatten).\"\"\"\n",
    "    units = []\n",
    "    sensors = [c for c in df.columns if c.startswith(\"s\")]\n",
    "    grouped = df.groupby(\"unit\")\n",
    "    for u, g in grouped:\n",
    "        row = {\"unit\": u, \"cycles_count\": g[\"cycle\"].nunique(), \"cycle_length\": g[\"cycle\"].max() - g[\"cycle\"].min() + 1}\n",
    "        # primeros y últimos valores por sensor (store as semicolon-separated)\n",
    "        first_vals = {f\"first_{s}\": g.iloc[0][s] for s in sensors}\n",
    "        last_vals = {f\"last_{s}\": g.iloc[-1][s] for s in sensors}\n",
    "        row.update(first_vals)\n",
    "        row.update(last_vals)\n",
    "        units.append(row)\n",
    "    return pd.DataFrame(units)\n",
    "\n",
    "def select_representative_units(df, n_random=3):\n",
    "    \"\"\"Seleccionar 6 unidades: min length, median length, max length, y 3 aleatorias distintas.\"\"\"\n",
    "    lengths = df.groupby(\"unit\")[\"cycle\"].nunique().reset_index(name=\"len\")\n",
    "    min_u = int(lengths.sort_values(\"len\").iloc[0][\"unit\"])\n",
    "    max_u = int(lengths.sort_values(\"len\").iloc[-1][\"unit\"])\n",
    "    med_idx = int(len(lengths) // 2)\n",
    "    med_u = int(lengths.sort_values(\"len\").iloc[med_idx][\"unit\"])\n",
    "    # escoger 3 aleatorias distintas de las anteriores\n",
    "    pool = set(lengths[\"unit\"].unique()) - {min_u, med_u, max_u}\n",
    "    rnd = list(np.random.choice(list(pool), size=n_random, replace=False))\n",
    "    selected = [min_u, med_u, max_u] + rnd\n",
    "    return selected\n",
    "\n",
    "def rolling_features_by_unit(df, sensors, windows=(5,10,20)):\n",
    "    \"\"\"Ejemplo: calcular rolling mean/std y slope (OLS) en ventanas por unidad.\"\"\"\n",
    "    out = df.copy()\n",
    "    for w in windows:\n",
    "        for s in sensors:\n",
    "            out[f\"{s}_rm_{w}\"] = out.groupby(\"unit\")[s].transform(lambda x: x.rolling(window=w, min_periods=1).mean())\n",
    "            out[f\"{s}_rstd_{w}\"] = out.groupby(\"unit\")[s].transform(lambda x: x.rolling(window=w, min_periods=1).std().fillna(0))\n",
    "            # slope via simple linear regression on rolling window\n",
    "            def slope(x):\n",
    "                if len(x) < 2:\n",
    "                    return 0.0\n",
    "                idx = np.arange(len(x))\n",
    "                A = np.vstack([idx, np.ones(len(idx))]).T\n",
    "                m, _ = np.linalg.lstsq(A, x, rcond=None)[0]\n",
    "                return m\n",
    "            out[f\"{s}_slope_{w}\"] = out.groupby(\"unit\")[s].transform(lambda x: x.rolling(window=w, min_periods=2).apply(slope, raw=True).fillna(0))\n",
    "    return out\n",
    "\n",
    "def save_fig(fig, filepath):\n",
    "    \"\"\"Guardar figura con tight layout y resolución.\"\"\"\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(filepath, dpi=150)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbdf3af",
   "metadata": {},
   "source": [
    "# Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a70b5e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lectura OK: (20631, 26) (13096, 26) (100, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>cycle</th>\n",
       "      <th>op1</th>\n",
       "      <th>op2</th>\n",
       "      <th>op3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s12</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit  cycle     op1     op2    op3      s1      s2       s3       s4  \\\n",
       "0     1      1 -0.0007 -0.0004  100.0  518.67  641.82  1589.70  1400.60   \n",
       "1     1      2  0.0019 -0.0003  100.0  518.67  642.15  1591.82  1403.14   \n",
       "2     1      3 -0.0043  0.0003  100.0  518.67  642.35  1587.99  1404.20   \n",
       "\n",
       "      s5  ...     s12      s13      s14     s15   s16  s17   s18    s19  \\\n",
       "0  14.62  ...  521.66  2388.02  8138.62  8.4195  0.03  392  2388  100.0   \n",
       "1  14.62  ...  522.28  2388.07  8131.49  8.4318  0.03  392  2388  100.0   \n",
       "2  14.62  ...  522.42  2388.03  8133.23  8.4178  0.03  390  2388  100.0   \n",
       "\n",
       "     s20      s21  \n",
       "0  39.06  23.4190  \n",
       "1  39.00  23.4236  \n",
       "2  38.95  23.3442  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "col_names = [\"unit\",\"cycle\",\"op1\",\"op2\",\"op3\"] + [f\"s{i}\" for i in range(1,22)]\n",
    "train_path = RAW_DIR / \"train_FD001.txt\"\n",
    "test_path  = RAW_DIR / \"test_FD001.txt\"\n",
    "rul_path   = RAW_DIR / \"RUL_FD001.txt\"\n",
    "\n",
    "for p in (train_path, test_path, rul_path):\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"No existe: {p}\")\n",
    "\n",
    "train = pd.read_csv(train_path, sep=r\"\\s+\", header=None, names=col_names, engine=\"python\")\n",
    "test  = pd.read_csv(test_path,  sep=r\"\\s+\", header=None, names=col_names, engine=\"python\")\n",
    "rul_truth = pd.read_csv(rul_path, sep=r\"\\s+\", header=None, names=[\"RUL_true\"], engine=\"python\")\n",
    "\n",
    "print(\"Lectura OK:\", train.shape, test.shape, rul_truth.shape)\n",
    "display(train.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dad3407",
   "metadata": {},
   "source": [
    "# Resumen general y summary_stats.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f287d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summary_stats(train)\n",
    "summary.to_csv(EDA_OUT / \"summary_stats.csv\", index=False)\n",
    "\n",
    "# Guardar una imagen tabular legible (simple plot)\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "sns.heatmap(pd.DataFrame(summary.set_index(\"column\")[\"mean\"]), annot=True, fmt=\".2f\", cmap=\"vlag\", cbar=False, ax=ax)\n",
    "ax.set_title(\"Resumen (media) por columna — vista simplificada\")\n",
    "save_fig(fig, EDA_OUT / \"summary_stats_table.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ee73b2",
   "metadata": {},
   "source": [
    "# Chequeos de Calidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f37d7d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC summary:\n",
      "n_rows_train : 20631\n",
      "n_units_train : 100\n",
      "n_rows_test : 13096\n",
      "n_units_test : 100\n",
      "na_counts (sample): {'unit': 0, 'cycle': 0, 'op1': 0, 'op2': 0, 'op3': 0}\n",
      "cols_constant : 7 units\n",
      "duplicates : 0\n",
      "monotonicity_issues_units : 0 units\n"
     ]
    }
   ],
   "source": [
    "qc = {}\n",
    "qc[\"n_rows_train\"] = len(train)\n",
    "qc[\"n_units_train\"] = train[\"unit\"].nunique()\n",
    "qc[\"n_rows_test\"] = len(test)\n",
    "qc[\"n_units_test\"] = test[\"unit\"].nunique()\n",
    "qc[\"na_counts\"] = train.isna().sum().to_dict()\n",
    "qc[\"cols_constant\"] = [c for c in train.columns if train[c].nunique() <= 1]\n",
    "qc[\"duplicates\"] = train.duplicated().sum()\n",
    "# monotonicity por unit\n",
    "mono_issues = []\n",
    "for u, g in train.groupby(\"unit\"):\n",
    "    if not g[\"cycle\"].is_monotonic_increasing:\n",
    "        mono_issues.append(u)\n",
    "qc[\"monotonicity_issues_units\"] = mono_issues\n",
    "\n",
    "# imprimir resumen de QC\n",
    "print(\"QC summary:\")\n",
    "for k, v in qc.items():\n",
    "    if k == \"na_counts\":\n",
    "        print(\"na_counts (sample):\", {k: v[k] for k in list(v)[:5]})\n",
    "    else:\n",
    "        print(k, \":\", (v if not isinstance(v, list) else f\"{len(v)} units\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c0b52c",
   "metadata": {},
   "source": [
    "# Cálculo de RUL y guardado rul_per_unit.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d704e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rul, rul_per_unit = compute_rul(train)\n",
    "rul_per_unit.to_csv(EDA_OUT / \"rul_per_unit.csv\", index=False)\n",
    "\n",
    "# añadir RUL al dataframe train en memoria\n",
    "train = train_rul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9048f13d",
   "metadata": {},
   "source": [
    "# Count units vs cycles plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e17943",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = train.groupby(\"unit\")[\"cycle\"].nunique().reset_index(name=\"n_cycles\")\n",
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "sns.barplot(x=\"unit\", y=\"n_cycles\", data=counts, palette=\"viridis\", ax=ax)\n",
    "ax.set_title(\"Cycles por unit (FD001)\")\n",
    "ax.set_xlabel(\"Unit\")\n",
    "ax.set_ylabel(\"Number of cycles\")\n",
    "ax.set_xticks(ax.get_xticks()[::5]) \n",
    "save_fig(fig, EDA_OUT / \"count_units_cycles.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d7ba2c",
   "metadata": {},
   "source": [
    "# Selección de 6 unidades representativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cfea882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 unidades seleccionadas: [39, 79, 69, np.int64(64), np.int64(42), np.int64(97)]\n"
     ]
    }
   ],
   "source": [
    "selected_units = select_representative_units(train, n_random=3)\n",
    "print(\"6 unidades seleccionadas:\", selected_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c58c8",
   "metadata": {},
   "source": [
    "# Trajectory samples plot (6 unidades, sensors s2,s3,s7,s15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51b5886",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_plot = [\"s2\", \"s3\", \"s7\", \"s15\"]\n",
    "fig, axes = plt.subplots(6, len(sensors_plot), figsize=(16, 18), sharex=False)\n",
    "for i, u in enumerate(selected_units):\n",
    "    sub = train[train[\"unit\"]==u]\n",
    "    for j, s in enumerate(sensors_plot):\n",
    "        ax = axes[i, j]\n",
    "        ax.plot(sub[\"cycle\"], sub[s], label=f\"unit {u}\")\n",
    "        ax.set_title(f\"unit {u} - {s}\")\n",
    "        ax.set_xlabel(\"cycle\")\n",
    "        ax.set_ylabel(s)\n",
    "        ax.grid(True)\n",
    "save_fig(fig, EDA_OUT / \"trajectory_samples.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bf2d04",
   "metadata": {},
   "source": [
    "# Operative conditions (histograms y hexbin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6627c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize=(18,5))\n",
    "for i, op in enumerate([\"op1\",\"op2\",\"op3\"]):\n",
    "    sns.histplot(train[op], ax=ax[i], kde=False, bins=30)\n",
    "    ax[i].set_title(f\"Distribución {op}\")\n",
    "save_fig(fig, EDA_OUT / \"op_conditions_hist.png\")\n",
    "\n",
    "# hexbin sensor vs op (ejemplo s7 vs op1)\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "hb = ax.hexbin(train[\"op1\"], train[\"s7\"], gridsize=80, cmap=\"inferno\")\n",
    "ax.set_xlabel(\"op1\")\n",
    "ax.set_ylabel(\"s7\")\n",
    "ax.set_title(\"Hexbin s7 vs op1\")\n",
    "fig.colorbar(hb, ax=ax)\n",
    "save_fig(fig, EDA_OUT / \"sensor_vs_op_hexbin.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d774ea1",
   "metadata": {},
   "source": [
    "# Correlación (Pearson y Spearman) y heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5752451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = [c for c in train.columns if c.startswith(\"s\")]\n",
    "df_sensors = train[sensors].copy()\n",
    "\n",
    "pearson = df_sensors.corr(method=\"pearson\")\n",
    "spearman = df_sensors.corr(method=\"spearman\")\n",
    "\n",
    "# heatmap Pearson\n",
    "fig, ax = plt.subplots(figsize=(14,12))\n",
    "sns.heatmap(pearson, cmap=\"coolwarm\", center=0, annot=False, ax=ax)\n",
    "ax.set_title(\"Pearson correlation — sensors\")\n",
    "save_fig(fig, EDA_OUT / \"correlation_heatmap.png\")\n",
    "\n",
    "pearson.to_csv(EDA_OUT / \"pearson_sensors.csv\", index=True)\n",
    "spearman.to_csv(EDA_OUT / \"spearman_sensors.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1530be6d",
   "metadata": {},
   "source": [
    "# PCA (normalizar sensores y scree plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043b0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "sensors_scaled = scaler.fit_transform(df_sensors.fillna(0))\n",
    "pca = PCA(n_components=10, random_state=RANDOM_SEED)\n",
    "pca.fit(sensors_scaled)\n",
    "explained = pca.explained_variance_ratio_\n",
    "cum_explained = np.cumsum(explained)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.bar(range(1, len(explained)+1), explained, alpha=0.6, label=\"Individual\")\n",
    "ax.plot(range(1, len(explained)+1), cum_explained, \"-o\", color=\"k\", label=\"Cumulative\")\n",
    "ax.set_xlabel(\"PC\")\n",
    "ax.set_ylabel(\"Explained variance ratio\")\n",
    "ax.set_title(\"PCA Scree (first 10 components)\")\n",
    "ax.legend()\n",
    "save_fig(fig, EDA_OUT / \"pca_scree.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b968a4e3",
   "metadata": {},
   "source": [
    "# Temporal properties — ACF/PACF para 4 sensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216ec71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acf_sensors = [\"s2\",\"s3\",\"s7\",\"s15\"]\n",
    "# crear una figura con 4x2 subplots (ACF y PACF por sensor)\n",
    "fig, axes = plt.subplots(len(acf_sensors), 2, figsize=(14, 3*len(acf_sensors)))\n",
    "for i, s in enumerate(acf_sensors):\n",
    "    series = train.groupby(\"unit\")[s].apply(lambda x: x.reset_index(drop=True)).explode().astype(float)  # concatenación simplificada\n",
    "    u = selected_units[1]  # motor mediano\n",
    "    series_u = train[train[\"unit\"]==u][s].fillna(method=\"ffill\").values\n",
    "    ax1 = axes[i,0]\n",
    "    ax2 = axes[i,1]\n",
    "    plot_acf(series_u, lags=50, ax=ax1, title=f\"ACF {s} (unit {u})\")\n",
    "    plot_pacf(series_u, lags=50, ax=ax2, title=f\"PACF {s} (unit {u})\")\n",
    "save_fig(fig, EDA_OUT / \"acf_pacf_samples.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce84c636",
   "metadata": {},
   "source": [
    "# RUL trajectories plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d4034",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,2, figsize=(14,12))\n",
    "for ax, u in zip(axes.flatten(), selected_units):\n",
    "    sub = train[train[\"unit\"]==u]\n",
    "    ax.plot(sub[\"cycle\"], sub[\"RUL\"], marker=\"o\", linewidth=1)\n",
    "    ax.set_title(f\"Unit {u} — RUL vs cycle\")\n",
    "    ax.set_xlabel(\"cycle\")\n",
    "    ax.set_ylabel(\"RUL\")\n",
    "save_fig(fig, EDA_OUT / \"rul_trajectories.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc39b0dc",
   "metadata": {},
   "source": [
    "# Candidate features generation and top_features.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1423d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sensors = [\"s2\",\"s3\",\"s7\",\"s15\",\"s11\",\"s21\"]\n",
    "feats = []\n",
    "windows = [5,10,20]\n",
    "for s in example_sensors:\n",
    "    for w in windows:\n",
    "        feats.append({\n",
    "            \"name\": f\"{s}_rm_{w}\",\n",
    "            \"description\": f\"Rolling mean of {s} over window {w}\",\n",
    "            \"rationale\": \"Smooths short-term noise and captures trend\"\n",
    "        })\n",
    "        feats.append({\n",
    "            \"name\": f\"{s}_rstd_{w}\",\n",
    "            \"description\": f\"Rolling std of {s} over window {w}\",\n",
    "            \"rationale\": \"Captures local variability and abrupt changes\"\n",
    "        })\n",
    "    feats.append({\n",
    "        \"name\": f\"{s}_slope_10\",\n",
    "        \"description\": f\"Slope (OLS) of {s} over window 10\",\n",
    "        \"rationale\": \"Quantifies local increasing/decreasing trend\"\n",
    "    })\n",
    "# add proximity to max/min per unit\n",
    "feats.append({\"name\":\"proximity_to_max_s2\",\"description\":\"(max_s2_unit - s2)/max_s2_unit\",\"rationale\":\"Relative degradation distance to worst observed value\"})\n",
    "# limit to 12 top features\n",
    "top_feats = pd.DataFrame(feats)[:12]\n",
    "top_feats.to_csv(EDA_OUT / \"top_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db04273",
   "metadata": {},
   "source": [
    "# Leakage checks y recomendaciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60aac9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leakage checks - suspicious columns: []\n"
     ]
    }
   ],
   "source": [
    "# Leakage simple check: verificar que RUL no se haya usado para crear features, y que rolling features usan pasado\n",
    "leakage_issues = []\n",
    "for c in train.columns:\n",
    "    if \"future\" in c.lower():\n",
    "        leakage_issues.append(c)\n",
    "\n",
    "print(\"Leakage checks - suspicious columns:\", leakage_issues)\n",
    "# Documentar manualmente si algo más se detecta. Para rolling: todas las funciones de rolling definidas usan transform(groupby.. rolling) con min_periods and do not peek into future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce55bc4",
   "metadata": {},
   "source": [
    "# Exports adicionales y checks automáticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec297a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checks summary: {'files_exist': True, 'rul_rows_eq_train': True, 'summary_has_missing_pct': True}\n"
     ]
    }
   ],
   "source": [
    "# Guardar per_unit_stats\n",
    "per_unit = per_unit_stats(train)\n",
    "per_unit.to_csv(EDA_OUT / \"per_unit_stats.csv\", index=False)\n",
    "\n",
    "# Save additional meta info\n",
    "meta = {\n",
    "    \"n_rows_train\": int(len(train)),\n",
    "    \"n_units_train\": int(train[\"unit\"].nunique()),\n",
    "    \"n_rows_test\": int(len(test)),\n",
    "    \"n_units_test\": int(test[\"unit\"].nunique()),\n",
    "    \"selected_units\": selected_units\n",
    "}\n",
    "pd.Series(meta).to_frame(\"value\").to_csv(EDA_OUT / \"eda_metadata.csv\")\n",
    "\n",
    "# Validaciones automáticas mínimas\n",
    "checks = {}\n",
    "checks[\"files_exist\"] = all((EDA_OUT / f).exists() for f in [\n",
    "    \"summary_stats.csv\",\"per_unit_stats.csv\",\"top_features.csv\",\"rul_per_unit.csv\",\n",
    "    \"count_units_cycles.png\",\"trajectory_samples.png\",\"correlation_heatmap.png\",\n",
    "    \"pca_scree.png\",\"rul_trajectories.png\",\"acf_pacf_samples.png\",\"sensor_vs_op_hexbin.png\",\n",
    "    \"summary_stats_table.png\"\n",
    "])\n",
    "checks[\"rul_rows_eq_train\"] = (len(pd.read_csv(EDA_OUT / \"rul_per_unit.csv\")) == len(train))\n",
    "checks[\"summary_has_missing_pct\"] = \"missing_pct\" in pd.read_csv(EDA_OUT / \"summary_stats.csv\").columns\n",
    "\n",
    "print(\"Checks summary:\", checks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5234059a",
   "metadata": {},
   "source": [
    "# Verificación final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f533727d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDA completo — artifacts guardados en ./eda_outputs/\n",
      "Número de unidades procesadas: 100\n",
      "Unidades seleccionadas (6): [39, 79, 69, np.int64(64), np.int64(42), np.int64(97)]\n",
      "Top features file: c:\\Users\\jucep\\OneDrive\\Escritorio\\CMAPSS\\Mantenimiento-Predictivo-CMAPSS\\EDA\\eda_outputs\\top_features.csv\n",
      "Recomendación rápida: usar StandardScaler para sensores; ventanas iniciales prioritarias: 5, 10, 20; priorizar slopes y rolling std como features.\n"
     ]
    }
   ],
   "source": [
    "print(\"EDA completo — artifacts guardados en ./eda_outputs/\")\n",
    "print(f\"Número de unidades procesadas: {train['unit'].nunique()}\")\n",
    "print(\"Unidades seleccionadas (6):\", selected_units)\n",
    "print(\"Top features file:\", EDA_OUT / \"top_features.csv\")\n",
    "print(\"Recomendación rápida: usar StandardScaler para sensores; ventanas iniciales prioritarias: 5, 10, 20; priorizar slopes y rolling std como features.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
